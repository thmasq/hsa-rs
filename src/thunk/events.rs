use crate::kfd::device::KfdDevice;
use crate::kfd::ioctl::{
    AMDKFD_IOC_CREATE_EVENT, AMDKFD_IOC_DESTROY_EVENT, AMDKFD_IOC_RESET_EVENT,
    AMDKFD_IOC_SET_EVENT, AMDKFD_IOC_WAIT_EVENTS, CreateEventArgs, DestroyEventArgs,
    EventData as IoctlEventData, KFD_IOC_WAIT_RESULT_TIMEOUT, ResetEventArgs, SetEventArgs,
    WaitEventsArgs,
};
use crate::kfd::sysfs::HsaNodeProperties;
use crate::thunk::memory::{Allocation, MemoryManager};
use std::collections::HashMap;
use std::mem;
use std::os::fd::RawFd;
use std::ptr;

/// The hardware limit for signal events per process.
pub const KFD_SIGNAL_EVENT_LIMIT: usize = 4096;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(u32)]
pub enum HsaEventType {
    Signal = 0,
    NodeChange = 1,
    DeviceStateChange = 2,
    HwException = 3,
    SystemEvent = 4,
    DebugEvent = 5,
    ProfileEvent = 6,
    QueueEvent = 7,
    Memory = 8,
}

impl HsaEventType {
    /// System events are generated by the hardware/driver and cannot be manually signaled by userspace.
    #[must_use]
    pub fn is_system_event(&self) -> bool {
        !matches!(self, HsaEventType::Signal | HsaEventType::DebugEvent)
    }
}

/// Represents the user-space sync variable associated with an event.
#[derive(Debug, Clone, Copy)]
#[repr(C)]
pub struct HsaSyncVar {
    pub user_data: *mut std::ffi::c_void,
    pub sync_var_size: u64,
}

/// Descriptor used to create a new event.
#[derive(Debug, Clone)]
pub struct HsaEventDescriptor {
    pub event_type: HsaEventType,
    pub node_id: u32,
    pub sync_var: HsaSyncVar,
}

#[derive(Debug, Clone)]
pub enum HsaEventDataPayload {
    /// Standard payload for Signal events (`SyncVar`).
    SyncVar(HsaSyncVar),
    /// Payload for Memory Exception events.
    MemoryAccessFault(HsaMemoryAccessFault),
    /// Payload for Hardware Exception events.
    HwException(HsaHwException),
    /// Placeholder for other events (`NodeChange`, `DeviceStateChange`, etc.).
    None,
}

/// Details of a memory access fault reported by the GPU.
#[derive(Debug, Clone)]
pub struct HsaMemoryAccessFault {
    /// The logical Node ID where the fault occurred.
    pub node_id: u32,
    /// The virtual address that caused the fault.
    pub virtual_address: u64,
    /// Specific failure flags.
    pub failure: HsaAccessAttributeFailure,
    /// Whether this fault is unrecoverable.
    pub is_fatal: bool,
}

#[derive(Debug, Clone, Copy)]
pub struct HsaAccessAttributeFailure {
    pub not_present: bool,
    pub read_only: bool,
    pub no_execute: bool,
    pub ecc_error: bool,
    pub imprecise: bool,
    pub error_type: u32,
}

/// Details of a hardware exception (e.g., reset).
#[derive(Debug, Clone)]
pub struct HsaHwException {
    pub node_id: u32,
    pub reset_type: u32,
    pub memory_lost: bool,
    pub reset_cause: u32,
}

/// The main Event Object structure.
///
/// This struct maintains state (`last_event_age`) required to correctly detecting
/// signal firing, especially for Auto-Reset events.
#[derive(Debug, Clone)]
pub struct HsaEvent {
    pub event_id: u32,
    pub event_type: HsaEventType,
    pub payload: HsaEventDataPayload,
    pub hw_data1: u64,
    pub hw_data2: u64,
    pub hw_data3: u32,
    pub last_event_age: u64,
}

/// Manages the global context for events, specifically the Events Page.
pub struct EventManager {
    /// The shared memory page used by the GPU to write signal events.
    /// This is allocated once per process/device context.
    events_page: Option<Allocation>,

    /// Mapping from Kernel GPU IDs to Logical Node IDs.
    /// Required to translate `gpu_id` in exception reports back to the user-facing `node_id`.
    gpu_to_node_map: HashMap<u32, u32>,
}

impl EventManager {
    /// Initialize the `EventManager`.
    ///
    /// This builds the `gpu_to_node_map` immediately to ensure O(1) lookups during event waits.
    #[must_use]
    pub fn new(nodes: &[HsaNodeProperties]) -> Self {
        let mut gpu_to_node_map = HashMap::new();
        for (idx, node) in nodes.iter().enumerate() {
            // Map the Kernel GPU ID to the index in the node list (Logical Node ID).
            if node.kfd_gpu_id != 0 {
                gpu_to_node_map.insert(node.kfd_gpu_id, idx as u32);
            }
        }

        Self {
            events_page: None,
            gpu_to_node_map,
        }
    }

    /// Creates a new HSA Event.
    ///
    /// If this is the first signal event created, it automatically allocates the
    /// hardware Events Page on the GPU associated with the event's `node_id`.
    pub fn create_event(
        &mut self,
        device: &KfdDevice,
        memory_manager: &mut MemoryManager,
        drm_fd: RawFd,
        desc: &HsaEventDescriptor,
        manual_reset: bool,
        is_signaled: bool,
    ) -> Result<HsaEvent, i32> {
        let mut args = CreateEventArgs::default();
        args.event_type = desc.event_type as u32;
        args.node_id = desc.node_id;
        args.auto_reset = (!manual_reset) as u32;

        // 1. Ensure Events Page exists.
        if self.events_page.is_none() {
            let alloc_size = KFD_SIGNAL_EVENT_LIMIT * 8;

            // Use GTT (System Memory) instead of VRAM.
            // This ensures CPU access (mapped) and Coherency.
            let events_alloc = memory_manager
                .allocate_gtt(device, alloc_size, desc.node_id, drm_fd)
                .map_err(|e| {
                    eprintln!("Failed to allocate events page: {:?}", e);
                    e
                })?;

            // Zero the memory
            if !events_alloc.ptr.is_null() {
                unsafe { ptr::write_bytes(events_alloc.ptr, 0, alloc_size) };
            }

            self.events_page = Some(events_alloc);
        }

        // 2. Setup arguments with the allocated page handle.
        // KFD requires the Buffer Object (BO) Handle for the event page.
        if let Some(alloc) = &self.events_page {
            args.event_page_offset = alloc.handle;
        }

        // 3. Call Create Event IOCTL
        if let Err(e) = unsafe { device.ioctl(AMDKFD_IOC_CREATE_EVENT, &mut args) } {
            eprintln!("AMDKFD_IOC_CREATE_EVENT failed: {e:?}");
            return Err(-1);
        }

        // 4. Calculate HW Address
        // The HW address is the CPU-mapped pointer to the specific slot in the events page.
        // This allows userspace to poll the event slot directly if needed.
        let mut hw_data2 = 0;
        if let Some(alloc) = &self.events_page {
            if args.event_slot_index < KFD_SIGNAL_EVENT_LIMIT as u32 {
                let base = alloc.ptr as u64;
                hw_data2 = base + (args.event_slot_index as u64 * 8);
            }
        }

        let event = HsaEvent {
            event_id: args.event_id,
            event_type: desc.event_type,
            payload: HsaEventDataPayload::SyncVar(desc.sync_var),
            hw_data1: args.event_id as u64,
            hw_data2,
            hw_data3: args.event_trigger_data,
            last_event_age: 0,
        };

        // 5. Set Initial Signal State (if requested)
        // System events (like Exceptions) cannot be manually signaled.
        if is_signaled && !desc.event_type.is_system_event() {
            let mut set_args = SetEventArgs {
                event_id: args.event_id,
                pad: 0,
            };
            if let Err(_) = unsafe { device.ioctl(AMDKFD_IOC_SET_EVENT, &mut set_args) } {
                self.destroy_event(device, &event).ok();
                return Err(-1);
            }
            // Note: We do not manually increment `last_event_age` here because the
            // kernel maintains the authoritative age. The next `wait` call will
            // retrieve the updated age (1) from the kernel, see it matches 0 < 1,
            // and correctly report the event as signaled.
        }

        Ok(event)
    }

    pub fn destroy_event(&self, device: &KfdDevice, event: &HsaEvent) -> Result<(), i32> {
        let mut args = DestroyEventArgs {
            event_id: event.event_id,
            pad: 0,
        };

        if let Err(e) = unsafe { device.ioctl(AMDKFD_IOC_DESTROY_EVENT, &mut args) } {
            eprintln!("AMDKFD_IOC_DESTROY_EVENT failed: {e:?}");
            return Err(-1);
        }
        Ok(())
    }

    pub fn set_event(&self, device: &KfdDevice, event: &HsaEvent) -> Result<(), i32> {
        if event.event_type.is_system_event() {
            return Err(-1); // Cannot manually set system events
        }

        let mut args = SetEventArgs {
            event_id: event.event_id,
            pad: 0,
        };

        if let Err(_) = unsafe { device.ioctl(AMDKFD_IOC_SET_EVENT, &mut args) } {
            return Err(-1);
        }
        Ok(())
    }

    pub fn reset_event(&self, device: &KfdDevice, event: &HsaEvent) -> Result<(), i32> {
        if event.event_type.is_system_event() {
            return Err(-1);
        }

        let mut args = ResetEventArgs {
            event_id: event.event_id,
            pad: 0,
        };

        if let Err(_) = unsafe { device.ioctl(AMDKFD_IOC_RESET_EVENT, &mut args) } {
            return Err(-1);
        }
        Ok(())
    }

    /// Waits on one or more events.
    ///
    /// # Arguments
    /// * `events` - A mutable slice of `HsaEvent` references. Mutable because internal state
    ///              (`last_event_age` and exception payloads) is updated.
    /// * `wait_all` - If true, blocks until *all* events are signaled.
    /// * `timeout_ms` - Timeout in milliseconds.
    ///
    /// # Returns
    /// * `Ok(Vec<usize>)`: A list of indices into the `events` slice corresponding to the events
    ///   that were detected as signaled.
    ///   - This handles **Auto-Reset** events correctly by comparing event age.
    ///   - If `wait_all` is true, this will contain all valid indices.
    /// * `Err(i32)`: Status code (e.g., -31 for Timeout).
    pub fn wait_on_multiple_events(
        &self,
        device: &KfdDevice,
        events: &mut [&mut HsaEvent],
        wait_all: bool,
        timeout_ms: u32,
    ) -> Result<Vec<usize>, i32> {
        if events.is_empty() {
            return Err(-1);
        }

        // 1. Prepare input array for IOCTL
        // We map our high-level HsaEvent to the raw `struct kfd_event_data`.
        let mut ioctl_events: Vec<IoctlEventData> = events
            .iter()
            .map(|e| {
                let mut data: IoctlEventData = unsafe { mem::zeroed() };
                data.event_id = e.event_id;
                data.kfd_event_data_ext = 0;

                // CRITICAL: Pass the last known age to the kernel.
                // The kernel compares this against the hardware's current age.
                // If hardware_age > last_event_age, the kernel considers it signaled.
                if e.event_type == HsaEventType::Signal {
                    data.payload.signal_event_data.last_event_age = e.last_event_age;
                }
                data
            })
            .collect();

        let mut args = WaitEventsArgs {
            events_ptr: ioctl_events.as_mut_ptr() as u64,
            num_events: ioctl_events.len() as u32,
            wait_for_all: wait_all as u32,
            timeout: timeout_ms,
            wait_result: 0,
        };

        // 2. Call Wait IOCTL
        // This blocks until the condition is met or timeout.
        let ret = unsafe { device.ioctl(AMDKFD_IOC_WAIT_EVENTS, &mut args) };

        if ret.is_err() {
            return Err(-1);
        }

        if args.wait_result == KFD_IOC_WAIT_RESULT_TIMEOUT {
            return Err(-31); // HSAKMT_STATUS_WAIT_TIMEOUT
        }

        // 3. Process results and identify which events signaled
        let mut signaled_indices = Vec::new();

        // Pass 1: Check for definitive hardware signals (Age change or Exception data)
        for (i, ioctl_evt) in ioctl_events.iter().enumerate() {
            let event = &mut events[i];

            match event.event_type {
                HsaEventType::Signal => unsafe {
                    let new_age = ioctl_evt.payload.signal_event_data.last_event_age;

                    // If the age returned by kernel is greater than what we had, it fired.
                    // This mechanism is robust against Auto-Reset: even if the signal bit
                    // is already cleared, the age counter increment persists.
                    if new_age > event.last_event_age {
                        event.last_event_age = new_age;
                        signaled_indices.push(i);
                    }
                },
                HsaEventType::Memory => unsafe {
                    // KFD indicates an exception payload by setting the gpu_id field.
                    if ioctl_evt.payload.memory_exception_data.gpu_id != 0 {
                        let data = &ioctl_evt.payload.memory_exception_data;

                        // Use the map to get the real Node ID.
                        // If the GPU ID is unknown, we default to 0 (system).
                        let node_id = *self.gpu_to_node_map.get(&data.gpu_id).unwrap_or(&0);

                        event.payload =
                            HsaEventDataPayload::MemoryAccessFault(HsaMemoryAccessFault {
                                node_id,
                                virtual_address: data.va,
                                failure: HsaAccessAttributeFailure {
                                    not_present: data.failure.not_present != 0,
                                    read_only: data.failure.read_only != 0,
                                    no_execute: data.failure.no_execute != 0,
                                    imprecise: data.failure.imprecise != 0,
                                    ecc_error: data.error_type == 1 || data.error_type == 2,
                                    error_type: data.error_type,
                                },
                                is_fatal: true,
                            });

                        signaled_indices.push(i);
                    }
                },
                HsaEventType::HwException => unsafe {
                    if ioctl_evt.payload.hw_exception_data.gpu_id != 0 {
                        let data = &ioctl_evt.payload.hw_exception_data;

                        let node_id = *self.gpu_to_node_map.get(&data.gpu_id).unwrap_or(&0);

                        event.payload = HsaEventDataPayload::HwException(HsaHwException {
                            node_id,
                            reset_type: data.reset_type,
                            memory_lost: data.memory_lost != 0,
                            reset_cause: data.reset_cause,
                        });

                        signaled_indices.push(i);
                    }
                },
                _ => {
                    // System events usually don't track age, so if wait returned, assume signaled.
                    signaled_indices.push(i);
                }
            }
        }

        // Pass 2: Fallback for Software Signals
        // If KFD returned Success (Wait Complete), but we found no hardware age changes,
        // it means we were woken by a software signal (set_event) which doesn't update age.
        if signaled_indices.is_empty() && args.wait_result == 0 {
            for (i, event) in events.iter().enumerate() {
                // We assume Signal events might be the culprit.
                // Exceptions/System events would have been caught above by data presence.
                if event.event_type == HsaEventType::Signal {
                    signaled_indices.push(i);
                }
            }
        }

        Ok(signaled_indices)
    }
}
